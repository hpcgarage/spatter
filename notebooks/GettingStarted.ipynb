{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b9173-92c1-41eb-bdce-32eae972ff5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import pickle\n",
    "import subprocess\n",
    "import spatter_util\n",
    "import warnings\n",
    "import importlib\n",
    "importlib.reload(spatter_util)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8067f4a-e0de-43ef-a4ce-0893f8c7e583",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting Started with Spatter\n",
    "\n",
    "Spatter is a memory benchmark suite designed to easily run a wide range of memory patterns on CPUs and GPUs. At the core of Spatter sit five kernels, Gather, Scatter, Concurrent Gather/Scatter a.k.a. GS, MultiGather, and MultiScatter. A detailed explanation of the Gather and Scatter kernels can be found in our MEMSYS'20 paper, which you can read [here](https://dl.acm.org/doi/abs/10.1145/3422575.3422794). The remaining 3 kernels are briefly described below:\n",
    "\n",
    "Concurrent Gather/Scatter:\n",
    "    `A[j[:]] = B[i[:]]`\n",
    "\n",
    "MultiScatter:\n",
    "    `A[j1[j2[:]]] = B[:]`\n",
    "\n",
    "MultiGather:\n",
    "    `A[:] = B[i1[i2[:]]]`\n",
    "\n",
    "This notebook will guide you through building and running standard Spatter testsuites and will add the results to the plots found in our  Specifically, we will be adding your data to Figures 3, 5, and 9 from the paper.\n",
    "\n",
    "To get started, fill out the information in the table below about your system. The data that comes pre-populated in this notebook was generated on an M1 Macbook Air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d4942-979c-4d34-b3bd-0ac53a830ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "platform_name  = 'M1'  # Used for plot legends\n",
    "system_type    = 'cpu' # Change to 'gpu' if you build with the CUDA backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab73fa9-4862-4ed6-97ec-f5007a44f030",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building\n",
    "\n",
    "We're going to build the OpenMP backend. You may use a different build option from [Build.md](../Build.md) if you like. If you change the build command, change `build_dir` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2a970-975c-4db3-ba11-f2af46e2993a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code_dir      = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "build_dir     = f'{code_dir}/build_openmp'\n",
    "notebook_dir  = os.getcwd()\n",
    "build_command = 'cmake -DUSE_OPENMP=1 -B build_openmp'\n",
    "exe           = f'{build_dir}/spatter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6da7ad-6e4b-41e5-9aa3-a78494a787db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(code_dir)\n",
    "subprocess.run([f'{build_command}'],shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "\n",
    "os.chdir(build_dir)\n",
    "subprocess.run(['make', '-j4'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "\n",
    "os.chdir(notebook_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8fdf8b-ce49-40c6-8178-5d5c58047cd6",
   "metadata": {},
   "source": [
    "## Understanding Spatter Output\n",
    "First, let's look at how we can use Spatter to get a number similar to what John McCalpin's [STREAM](https://www.cs.virginia.edu/stream/) would give us. \n",
    "\n",
    "To accomplish this in Spatter, we want to create a pattern that will read in every element of an array with no reuse. This means we want an index buffer containing the numbers $0$ to $N-1$, and a `delta` of $N$. The value of $N$ does not change the data that is read, but may have performance implications for the architecture you're running on. A good value for CPUs is 8, and a good value for GPUs is 256. We want to run this test as a sanity check before running the more interested tests. \n",
    "\n",
    "One caveat when comparing to STREAM is that Spatter is designed to only produce Reads in Gather mode, and to only produce writes in Scatter mode. The numbers should still be similar, however. \n",
    "\n",
    "We'll write this one out by hand so we can look at some of the options Spatter supports. After this, we'll just run the scripts that run the standard testsuites. This test will require 1GiB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628eacd-b986-4be2-a527-8b381faa9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8                         # Index buffer length, as described above\n",
    "index = f'-pUNIFORM:{N}:1:NR' # This is a shorthand that Spatter supports meaning \"Uniform stride, length N, gap 1, no reuse\n",
    "                              # You could also write -p0,1,2,3,4,5,6,7\n",
    "delta = f'-d{N}'              # This is the delta applied to the base address between gathers/scatters\n",
    "count = f'-l{2**24}'          # The -l (--count) option specifies how many gathers or scatters to perform\n",
    "                              # With an index buffer of length 8, and 8 bytes per double, this will be 2^3 * 2^3 * 2^24 = 1GiB of data read\n",
    "verbosity = '-v2'             # Verbosity level (level >= 2 to print run configs)\n",
    "\n",
    "_ = subprocess.run([exe, index, delta, count, verbosity], stdout=open('tmp.txt','w'))\n",
    "with open('tmp.txt','r') as file:\n",
    "    print(file.read())\n",
    "os.remove('tmp.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c9554-6f4a-4bb9-9732-61a562f1e749",
   "metadata": {},
   "source": [
    "### Spatter Output\n",
    "\n",
    "There are 4 sections in the above output:\n",
    "1. Build information\n",
    "1. Run configuations\n",
    "\n",
    "    - In this case there is only one. Spatter supports a JSON input to specify multiple run configuations. This saves time allocating memory as it can be re-used between benchmark runs. \n",
    "        \n",
    "1. Time and effective bandwidth per configuration. \n",
    "\n",
    "    - In the run configuration, you'll see that \"agg\" is set to 10, meaning the configuation is an aggregate across 10 runs. We take the minimum time of all aggregated runs. \n",
    "    \n",
    "1. Summary information\n",
    "\n",
    "    - These numbers serve to summarize performance across all the the run configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a794ab-aadd-42ef-8a94-cf19f9628485",
   "metadata": {},
   "source": [
    "## Standard Suite 1: STREAM-like\n",
    "\n",
    "Let's run the STREAM-like suite. This suite does runs each of the three kernels on patterns that read and write continuous buffers, much like STREAM. The difference is that the gather kernel only performs reads, and the the scatter kernel only performs writes. The GS kernel does both, and while this kernel does allow you you to specify different gather and scatter offsets, this test will set both to be `[0,1,2,3,4,5,6,7]`.\n",
    "\n",
    "We won't make a plot from this data, but we'll use this to see how the other suites are run. This test will require 2GiB to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f2479-86eb-44ca-a3f7-e672c92a1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = f'../standard-suite/basic-tests/{system_type}-stream.json'\n",
    "_ = subprocess.run([exe, f'-f{suite}', '-v2'], stdout=open(f'stream_custom{system_type}.txt','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7222d14-becf-48ec-9ed5-9633dcb67891",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df = spatter_util.file2df(f'stream_custom{system_type}.txt')\n",
    "\n",
    "print(f'Gather       Bandwidth: {stream_df[\"bw(MB/s)\"][1]} MB/s') # The second pattern is a gather kernel\n",
    "print(f'Scatter      Bandwidth: {stream_df[\"bw(MB/s)\"][0]} MB/s') # The first pattern is a scatter kernel\n",
    "print(f'GS           Bandwidth: {stream_df[\"bw(MB/s)\"][2]} MB/s') # The third pattern is a gather/scatter kernel\n",
    "print(f'MultiGather  Bandwidth: {stream_df[\"bw(MB/s)\"][4]} MB/s') # The fifth pattern is a multigather kernel\n",
    "print(f'MultiScatter Bandwidth: {stream_df[\"bw(MB/s)\"][3]} MB/s') # The fourth pattern is a multiscatter kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111a275-06be-489a-9119-74b75d9caafa",
   "metadata": {},
   "source": [
    "## Standard Suite 2: Uniform Stride\n",
    "\n",
    "This suite runs gather and scatter patterns at power of 2 strides, from 1 to 128. Because we are access doubles, a stride of 8 means we are accessing 1 element from every 64-byte cache line. We expect to see effective bandwidth roughly level out at this point, although this is not the case on all systems! You can check out the paper for more on this plot!\n",
    "\n",
    "This test will require 2GB of memory. The plots in the paper used 16 GB but we want this notebook to run quickly on laptops with less memory. The paper did not do experiments with the GS kernel, so we will not be using that kernel here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2595f-87c7-4a83-9c94-de81bce63ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the suite\n",
    "\n",
    "suite = f'../standard-suite/basic-tests/{system_type}-ustride.json'\n",
    "subprocess.run([exe, f'-f{suite}', '-v2'], stdout=open(f'ustride_custom{system_type}.txt','w'))\n",
    "ustride_df = spatter_util.file2df(f'ustride_custom{system_type}.txt')\n",
    "ustride_df = ustride_df.rename(columns={'bw(MB/s)':'bw'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec6c8e-238c-40a7-81b0-42643ace5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatter_util.ALLNAMES['customcpu'] = platform_name \n",
    "\n",
    "spatter_util.ustride_plot(ustride_df, 'Gather')\n",
    "spatter_util.ustride_plot(ustride_df, 'Scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87f40c-8384-45bd-8258-12649583b427",
   "metadata": {},
   "source": [
    "Your data should appear as white circles with a black outline. This corresponds to Figure 3 in the paper. If you build for GPU, and set the Configuration Information above appropriately, you can use this same process to recreate Figure 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c350000-2d71-4250-90ba-a6a12ed2f7cd",
   "metadata": {},
   "source": [
    "## Standard Suite 3: Application Patterns\n",
    "\n",
    "The plots for app patterns are much more complicated, but their strucure allows us to compare systems both in terms of the absolute bandwdith they utilize for each pattern (by looking at the y-value of the points) as well as the percent of the available bandwidth they utilize (by looking at the distance of each point from the y=x line, which represents STREAM or Stride-1 bandwidth. \n",
    "\n",
    "The plots in the paper contain patterns from PENNANT and LULESH. We'll run those two, but you can also run the Nekbone and AMG patterns if you like.\n",
    "\n",
    "The PENNANT patterns may take a couple minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adaa86-3a62-4ede-adda-e685c68ca927",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (system_type == 'cpu'):\n",
    "    lulesh_suite  = '../standard-suite/app-traces/lulesh.json'\n",
    "    pennant_suite = '../standard-suite/app-traces/pennant.json'\n",
    "else: \n",
    "    lulesh_suite  = '../standard-suite/app-traces/lulesh_gpu.json'\n",
    "    pennant_suite = '../standard-suite/app-traces/pennant_gpu.json'\n",
    "\n",
    "_=subprocess.run([exe, f'-f{lulesh_suite}', '-v2'], stdout=open(f'lulesh_custom{system_type}.txt','w'))\n",
    "_=subprocess.run([exe, f'-f{pennant_suite}', '-v2'], stdout=open(f'pennant_custom{system_type}.txt','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d69d3-01d7-44f7-8de9-67f755843abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lulesh  = spatter_util.file2df(f'lulesh_custom{system_type}.txt')\n",
    "df_pennant = spatter_util.file2df(f'pennant_custom{system_type}.txt')\n",
    "\n",
    "notebook_df    = pd.concat([df_lulesh, df_pennant], ignore_index=True)\n",
    "ustride_df     = spatter_util.file2df(f'ustride_custom{system_type}.txt') # Read this in again without re-naming\n",
    "notebook_df    = pd.concat([ustride_df, notebook_df], ignore_index=True) # Join data from ustride above, we need this for the y=x line on the plot\n",
    "notebook_system_type = system_type # Used by the plotting script\n",
    "\n",
    "# Optional - Remove systems from the plot that overlap with your system. The full list is ['bdw', 'npl', 'tx2', 'skx', 'clx', 'titan', 'p100', 'gv100']\n",
    "notebook_remove = ['bdw', 'npl', 'tx2', 'skx']\n",
    "\n",
    "# The plotting script also imports spatter_util so we can change values here\n",
    "spatter_util.ALLNAMES['customcpu'] = platform_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d02c6-b137-49db-83e5-4f4a3dcceb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll just call a scrip to make this one -- it's too complicated to include here\n",
    "# These plots may not render properly on python < 3.8\n",
    "%run -i 'bwbw_plot.py' 'Gather'\n",
    "%run -i 'bwbw_plot.py' 'Scatter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762df454-cc98-48d4-8f15-0d8f282bb2d9",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "- Dig into other Spatter options in the [README.md](https://github.com/hpcgarage/spatter#readme)\n",
    "\n",
    "- Capture app patterns for your app with our [GS_Patterns tracing tool](https://github.com/hpcgarage/gs_patterns).\n",
    "\n",
    "- See more experiments in our [paper](https://dl.acm.org/doi/abs/10.1145/3422575.3422794)\n",
    "\n",
    "## Issues and Improvements\n",
    "\n",
    "Have issues running this notebook? Have ideas for improving or extending Spatter? Submit an issue [here](https://github.com/hpcgarage/spatter/issues), or submit a PR!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
